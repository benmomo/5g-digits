{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aea572a",
   "metadata": {},
   "source": [
    "# Unit 2.1 - train baseline model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f86b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.19.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (3.12.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (3.15.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (0.5.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorflow==2.19.0) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.19.0) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0) (0.1.2)\n",
      "Requirement already satisfied: tf2onnx==1.16.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: numpy>=1.14.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (1.26.4)\n",
      "Requirement already satisfied: onnx>=1.4.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (1.16.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (2.32.5)\n",
      "Requirement already satisfied: six in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (1.17.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (25.9.23)\n",
      "Requirement already satisfied: protobuf~=3.20 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from tf2onnx==1.16.1) (3.20.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests->tf2onnx==1.16.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests->tf2onnx==1.16.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests->tf2onnx==1.16.1) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from requests->tf2onnx==1.16.1) (2025.11.12)\n",
      "Requirement already satisfied: onnx==1.16.2 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: onnxruntime==1.18.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnx==1.16.2) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnx==1.16.2) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnxruntime==1.18.1) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnxruntime==1.18.1) (25.9.23)\n",
      "Requirement already satisfied: packaging in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnxruntime==1.18.1) (25.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from onnxruntime==1.18.1) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from coloredlogs->onnxruntime==1.18.1) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime==1.18.1) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from sympy->onnxruntime==1.18.1) (1.3.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ikybe\\anaconda3\\envs\\unit21_5g\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Environmental setup. Install required libraries. Create an environment with conda/anaconda with python 3.10.X\n",
    "# In Windows, there is no tflite-runtime library (available on Linux, ARM, Android and other embedded systems)\n",
    "!pip install \"tensorflow==2.19.0\"\n",
    "!pip install \"tf2onnx==1.16.1\"\n",
    "!pip install \"onnx==1.16.2\" \"onnxruntime==1.18.1\"\n",
    "!pip install \"numpy==1.26.4\" matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cee87d-44bc-4cf7-92fb-98a4fb0c15b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Normalized X_train mean: -0.11823387 std: 0.99343055\n",
      "y_train min/max: 0 7\n",
      "Class distribution (train): [1091 1929 2215  493  426 1045  975   67]\n",
      "Class distribution (test):  [251 409 455 112 103 244 180  13]\n",
      "class_names: ['STANDING' 'SITTING' 'WALKING' 'WALKING_UPSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'RUNNING' 'LYING' 'DRINKING']\n",
      "Train: (8241, 100, 7) Val: (1766, 100, 7) Test: (1767, 100, 7)\n",
      "Classes: ['STANDING' 'SITTING' 'WALKING' 'WALKING_UPSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'RUNNING' 'LYING' 'DRINKING']\n"
     ]
    }
   ],
   "source": [
    "# imports and data loading\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "DATA_PATH = os.path.join(\"..\", \"data\",\"uca_ehar_preprocessed_win100_step50.npz\")\n",
    "npz = np.load(DATA_PATH)\n",
    "\n",
    "X_train = npz[\"X_train\"]\n",
    "y_train = npz[\"y_train\"]\n",
    "X_val   = npz[\"X_val\"]\n",
    "y_val   = npz[\"y_val\"]\n",
    "X_test  = npz[\"X_test\"]\n",
    "y_test  = npz[\"y_test\"]\n",
    "class_names = npz[\"class_names\"]\n",
    "\n",
    "\n",
    "# --- Normalize inputs: per-channel standardization ---\n",
    "\n",
    "# Compute mean and std ONLY on the training set\n",
    "train_mean = X_train.mean(axis=(0, 1), keepdims=True)   # shape (1, 1, 7)\n",
    "train_std  = X_train.std(axis=(0, 1), keepdims=True)    # shape (1, 1, 7)\n",
    "\n",
    "# Save it to a file\n",
    "norm_stats_path =  os.path.join(\"..\", \"data\",\"har_norm_stats.npz\")\n",
    "np.savez(norm_stats_path, mean=train_mean, std=train_std)\n",
    "\n",
    "# Avoid division by zero\n",
    "train_std[train_std == 0] = 1.0\n",
    "\n",
    "X_train_norm = (X_train - train_mean) / train_std\n",
    "X_val_norm   = (X_val   - train_mean) / train_std\n",
    "X_test_norm  = (X_test  - train_mean) / train_std\n",
    "\n",
    "X_train = X_train_norm\n",
    "X_val   = X_val_norm\n",
    "X_test  = X_test_norm\n",
    "\n",
    "print(\"Normalized X_train mean:\", X_train.mean(), \"std:\", X_train.std())\n",
    "\n",
    "print(\"y_train min/max:\", y_train.min(), y_train.max())\n",
    "print(\"Class distribution (train):\", np.bincount(y_train))\n",
    "print(\"Class distribution (test): \", np.bincount(y_test))\n",
    "print(\"class_names:\", class_names)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "print(\"Classes:\", class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32a65c8-112a-4294-b48c-4aa5d0736b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (100, 7) Num classes: 8\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot vectors:\n",
    "num_classes = len(class_names)\n",
    "\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val_cat   = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test_cat  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "input_shape = X_train.shape[1:]   # (window_size, num_channels), e.g. (100, 7)\n",
    "print(\"Input shape:\", input_shape, \"Num classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf47746-9b3c-449b-93d0-6438531809c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"har_baseline_cnn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"har_baseline_cnn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m20,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,504</span> (322.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,504\u001b[0m (322.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,992</span> (320.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,992\u001b[0m (320.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a CNN baseline model\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_baseline_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Dense head\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"har_baseline_cnn\")\n",
    "    return model\n",
    "\n",
    "model = build_baseline_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9232735-92e9-4f87-a6cc-bdcd848536bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce428155-5b7b-49ba-9a1b-791867a49bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7447 - loss: 0.6375 - val_accuracy: 0.5283 - val_loss: 1.1792 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8281 - loss: 0.3967 - val_accuracy: 0.6846 - val_loss: 0.6498 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8509 - loss: 0.3427 - val_accuracy: 0.8414 - val_loss: 0.3597 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8648 - loss: 0.3149 - val_accuracy: 0.8567 - val_loss: 0.3119 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8790 - loss: 0.2838 - val_accuracy: 0.8686 - val_loss: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8842 - loss: 0.2729 - val_accuracy: 0.8930 - val_loss: 0.2584 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8925 - loss: 0.2562 - val_accuracy: 0.8845 - val_loss: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8895 - loss: 0.2498 - val_accuracy: 0.9026 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8979 - loss: 0.2475 - val_accuracy: 0.9003 - val_loss: 0.2271 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8998 - loss: 0.2319 - val_accuracy: 0.9037 - val_loss: 0.2259 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9046 - loss: 0.2246 - val_accuracy: 0.8964 - val_loss: 0.2543 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9033 - loss: 0.2248 - val_accuracy: 0.9032 - val_loss: 0.2320 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9148 - loss: 0.2102\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9103 - loss: 0.2166 - val_accuracy: 0.9054 - val_loss: 0.2301 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9194 - loss: 0.1922 - val_accuracy: 0.9043 - val_loss: 0.2098 - learning_rate: 5.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.1820 - val_accuracy: 0.9088 - val_loss: 0.2124 - learning_rate: 5.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9280 - loss: 0.1767 - val_accuracy: 0.9094 - val_loss: 0.2242 - learning_rate: 5.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9221 - loss: 0.1815 - val_accuracy: 0.9145 - val_loss: 0.1996 - learning_rate: 5.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9306 - loss: 0.1715 - val_accuracy: 0.9207 - val_loss: 0.1991 - learning_rate: 5.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9300 - loss: 0.1690 - val_accuracy: 0.9185 - val_loss: 0.2037 - learning_rate: 5.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9259 - loss: 0.1734 - val_accuracy: 0.9162 - val_loss: 0.2056 - learning_rate: 5.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m126/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.1669\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9308 - loss: 0.1682 - val_accuracy: 0.9185 - val_loss: 0.1996 - learning_rate: 5.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9363 - loss: 0.1552 - val_accuracy: 0.9287 - val_loss: 0.1845 - learning_rate: 2.5000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9407 - loss: 0.1474 - val_accuracy: 0.9292 - val_loss: 0.1896 - learning_rate: 2.5000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9408 - loss: 0.1458 - val_accuracy: 0.9275 - val_loss: 0.1799 - learning_rate: 2.5000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9404 - loss: 0.1470 - val_accuracy: 0.9207 - val_loss: 0.1931 - learning_rate: 2.5000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.1405 - val_accuracy: 0.9224 - val_loss: 0.1969 - learning_rate: 2.5000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m126/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9438 - loss: 0.1341\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9437 - loss: 0.1374 - val_accuracy: 0.9224 - val_loss: 0.1962 - learning_rate: 2.5000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9482 - loss: 0.1315 - val_accuracy: 0.9343 - val_loss: 0.1758 - learning_rate: 1.2500e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9494 - loss: 0.1279 - val_accuracy: 0.9388 - val_loss: 0.1738 - learning_rate: 1.2500e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9477 - loss: 0.1271 - val_accuracy: 0.9337 - val_loss: 0.1752 - learning_rate: 1.2500e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9521 - loss: 0.1242 - val_accuracy: 0.9371 - val_loss: 0.1735 - learning_rate: 1.2500e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9504 - loss: 0.1259 - val_accuracy: 0.9292 - val_loss: 0.1894 - learning_rate: 1.2500e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9459 - loss: 0.1305 - val_accuracy: 0.9366 - val_loss: 0.1759 - learning_rate: 1.2500e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9534 - loss: 0.1212\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9528 - loss: 0.1199 - val_accuracy: 0.9354 - val_loss: 0.1799 - learning_rate: 1.2500e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9528 - loss: 0.1174 - val_accuracy: 0.9360 - val_loss: 0.1770 - learning_rate: 6.2500e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9540 - loss: 0.1167 - val_accuracy: 0.9366 - val_loss: 0.1748 - learning_rate: 6.2500e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1163\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9564 - loss: 0.1142 - val_accuracy: 0.9360 - val_loss: 0.1742 - learning_rate: 6.2500e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9573 - loss: 0.1113 - val_accuracy: 0.9394 - val_loss: 0.1696 - learning_rate: 3.1250e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9574 - loss: 0.1107 - val_accuracy: 0.9383 - val_loss: 0.1706 - learning_rate: 3.1250e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9550 - loss: 0.1125 - val_accuracy: 0.9360 - val_loss: 0.1799 - learning_rate: 3.1250e-05\n",
      "Restoring model weights from the end of the best epoch: 38.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    epochs=40,          # a bit more\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919f2313-7721-4e45-88f3-bc9812ff89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 92.98%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set (We ideally want something in the 90–95% range to match the narrative in the unit)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"Baseline test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912396dc-f1b2-434e-a78c-68c000eaa44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Keras model to: ..\\models\\har_baseline.keras\n",
      "INFO:tensorflow:Assets written to: ../models/har_baseline_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/har_baseline_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../models/har_baseline_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 7), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2739105789408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109937920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109946016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109949360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109944608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109943200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109951296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109952000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110365488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110364256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739109953232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110363904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110370240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110370944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110374112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110375872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110371296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110373584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110379216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110378512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110465376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2739110466080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Exported SavedModel to: ..\\models\\har_baseline_savedmodel\n"
     ]
    }
   ],
   "source": [
    "# Save the Keras model (backup)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#MODELS_DIR = Path(\"..\")\n",
    "#MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Save Keras-format backup\n",
    "keras_path = os.path.join(\"..\", \"models\", \"har_baseline.keras\")\n",
    "model.save(keras_path)  # SavedModel format\n",
    "print(\"Saved Keras model to:\", keras_path)\n",
    "\n",
    "# 2) Export TensorFlow SavedModel (NO extension, use model.export)\n",
    "saved_model_dir = Path(\"..\") / \"models\" / \"har_baseline_savedmodel\"\n",
    "\n",
    "# IMPORTANT: use export, not save\n",
    "model.export(saved_model_dir.as_posix())\n",
    "print(\"Exported SavedModel to:\", saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea195dd0-8c78-4853-a434-226c4cb9f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ikybe\\anaconda3\\envs\\unit21_5G\\lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ikybe\\anaconda3\\envs\\unit21_5G\\lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ikybe\\anaconda3\\envs\\unit21_5G\\lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ikybe\\anaconda3\\envs\\unit21_5G\\lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX model to: ..\\models\\har_baseline.onnx\n",
      "Size on disk: 327.15 KB\n"
     ]
    }
   ],
   "source": [
    "# Convert SavedModel → ONNX with tf2onnx\n",
    "\n",
    "import tf2onnx\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "onnx_path = MODELS_DIR / \"har_baseline.onnx\"\n",
    "\n",
    "spec = (tf.TensorSpec((None,) + input_shape, tf.float32, name=\"input\"),)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=spec,\n",
    "    opset=13,\n",
    ")\n",
    "\n",
    "onnx.save(onnx_model, onnx_path.as_posix())\n",
    "print(\"Saved ONNX model to:\", onnx_path)\n",
    "print(\"Size on disk: {:.2f} KB\".format(os.path.getsize(onnx_path) / 1024))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29fae255-5c18-4d13-aeb4-0ea4ca14a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: WALKING | True: WALKING\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "session = ort.InferenceSession(onnx_path.as_posix(), providers=[\"CPUExecutionProvider\"])\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "sample = X_test[0:1].astype(np.float32)   # ya normalizado\n",
    "out = session.run([output_name], {input_name: sample})[0]\n",
    "pred_idx = out.argmax()\n",
    "print(\"Pred:\", class_names[pred_idx], \"| True:\", class_names[y_test[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9d879-d54c-4b56-9383-6df042fbfc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:unit21_5G]",
   "language": "python",
   "name": "conda-env-unit21_5G-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
