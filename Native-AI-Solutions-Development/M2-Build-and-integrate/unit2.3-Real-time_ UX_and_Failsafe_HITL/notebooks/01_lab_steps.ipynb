{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aea572a",
   "metadata": {},
   "source": [
    "# Unit Real-Time UX & Failsafe (Human-in-the-Loop)\n",
    "\n",
    "In this notebook you will design the logic that transforms model outputs into safe, real-time actions for users.\n",
    "\n",
    "You will implement:\n",
    "- UX event mapping (prediction → action)\n",
    "- failsafe logic (uncertainty, instability, invalid inputs)\n",
    "- human-in-the-loop confirmation / override\n",
    "\n",
    "This notebook assumes you already have a working Safe Inference API from Unit 2.2 (or you can simulate model outputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644826b-141b-4638-93b1-9953e678d3c2",
   "metadata": {},
   "source": [
    "## Lab Step 1 - From Prediction to UX Event\n",
    "\n",
    "In this step, you will transform AI model outputs into user-facing UX events.\n",
    "The goal is to decide *what the system should do* based on predictions, confidence, and context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e11f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33d1ce-d14e-4287-a2c0-534a70520f16",
   "metadata": {},
   "source": [
    "### 1.1 Defining a UX Event\n",
    "\n",
    "A UX event represents what the system communicates or does after evaluating a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cee87d-44bc-4cf7-92fb-98a4fb0c15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UXEvent:\n",
    "    event_type: str        # e.g. \"NO_ACTION\", \"SHOW_ALERT\", \"REQUEST_CONFIRMATION\"\n",
    "    message: str           # user-facing message\n",
    "    severity: str          # \"low\", \"medium\", \"high\"\n",
    "    metadata: Dict[str, Any]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15bd43-41d2-4491-bde7-499332eeae1c",
   "metadata": {},
   "source": [
    "### 1.2 Mapping Predictions to UX Events\n",
    "\n",
    "We now define simple rules that map predictions, confidence, and context to UX events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b881420f-5d65-4117-b8c3-e5969e93e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction_to_event(activity: str, confidence: float, restricted_area: bool) -> UXEvent:\n",
    "    if confidence < 0.6:\n",
    "        return UXEvent(\n",
    "            event_type=\"NO_ACTION\",\n",
    "            message=\"Low confidence – no action taken.\",\n",
    "            severity=\"low\",\n",
    "            metadata={\"activity\": activity, \"confidence\": confidence}\n",
    "        )\n",
    "\n",
    "    if restricted_area and activity in [\"RUNNING\", \"CLIMBING\"]:\n",
    "        return UXEvent(\n",
    "            event_type=\"SHOW_ALERT\",\n",
    "            message=\"Risky activity detected in restricted area.\",\n",
    "            severity=\"high\",\n",
    "            metadata={\n",
    "                \"activity\": activity,\n",
    "                \"confidence\": confidence,\n",
    "                \"restricted_area\": restricted_area\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return UXEvent(\n",
    "        event_type=\"NO_ACTION\",\n",
    "        message=\"Normal activity.\",\n",
    "        severity=\"low\",\n",
    "        metadata={\"activity\": activity, \"confidence\": confidence}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3ac35",
   "metadata": {},
   "source": [
    "### 1.3 Simulating Different Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf47746-9b3c-449b-93d0-6438531809c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UXEvent(event_type='SHOW_ALERT', message='Risky activity detected in restricted area.', severity='high', metadata={'activity': 'RUNNING', 'confidence': 0.92, 'restricted_area': True})\n",
      "UXEvent(event_type='NO_ACTION', message='Normal activity.', severity='low', metadata={'activity': 'WALKING', 'confidence': 0.85})\n",
      "UXEvent(event_type='NO_ACTION', message='Low confidence – no action taken.', severity='low', metadata={'activity': 'RUNNING', 'confidence': 0.45})\n",
      "UXEvent(event_type='NO_ACTION', message='Normal activity.', severity='low', metadata={'activity': 'SITTING', 'confidence': 0.8})\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    (\"RUNNING\", 0.92, True),\n",
    "    (\"WALKING\", 0.85, True),\n",
    "    (\"RUNNING\", 0.45, True),\n",
    "    (\"SITTING\", 0.80, False),\n",
    "]\n",
    "\n",
    "for activity, confidence, restricted in test_cases:\n",
    "    event = map_prediction_to_event(activity, confidence, restricted)\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c62789-ac63-49db-ba13-098c6e820f25",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "Observe how small changes in confidence or context change the resulting UX event.\n",
    "Why is this behaviour important for user trust and safety?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1d8dc-019b-4d88-b19c-ece126a1a1b6",
   "metadata": {},
   "source": [
    "## Lab Step 2 – Implementing Failsafe Logic\n",
    "\n",
    "In this step, you will extend the decision logic by adding failsafe mechanisms.\n",
    "The goal is to handle uncertainty and instability in a safe and controlled way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc7cc-4f61-4797-89b5-351996b51b54",
   "metadata": {},
   "source": [
    "### 2.1 Detecting Prediction Instability\n",
    "\n",
    "Rapid changes in predicted activities may indicate uncertainty rather than real changes.\n",
    "We detect instability by analysing recent predictions over a short time window.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc8ef44-b0cb-45a1-8016-51e680a65d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def is_unstable(predictions: List[str], max_changes: int = 2) -> bool:\n",
    "    changes = sum(\n",
    "        1 for i in range(1, len(predictions))\n",
    "        if predictions[i] != predictions[i - 1]\n",
    "    )\n",
    "    return changes > max_changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39937ffc-ded1-4e4c-8e79-e3519589380b",
   "metadata": {},
   "source": [
    "### 2.2 Applying Failsafe Rules\n",
    "\n",
    "If predictions are unstable, the system should avoid triggering high-severity alerts.\n",
    "Instead, it may request confirmation or take no action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fc783d-527b-49ff-93d2-ee2cac1c8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_failsafe(event: UXEvent, unstable: bool) -> UXEvent:\n",
    "    if unstable and event.event_type == \"SHOW_ALERT\":\n",
    "        return UXEvent(\n",
    "            event_type=\"REQUEST_CONFIRMATION\",\n",
    "            message=\"Unstable detection – user confirmation required.\",\n",
    "            severity=\"medium\",\n",
    "            metadata=event.metadata\n",
    "        )\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc0375-1df8-42a1-8cf3-169af88165c8",
   "metadata": {},
   "source": [
    "### 2.3 Testing Failsafe Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4b238c-5578-4534-85ef-cebb46b9d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable sequence unstable?: False\n",
      "Unstable sequence unstable?: True\n",
      "Event without failsafe: UXEvent(event_type='SHOW_ALERT', message='Risky activity detected.', severity='high', metadata={})\n",
      "Event with failsafe: UXEvent(event_type='REQUEST_CONFIRMATION', message='Unstable detection – user confirmation required.', severity='medium', metadata={})\n"
     ]
    }
   ],
   "source": [
    "recent_predictions_stable = [\"WALKING\", \"WALKING\", \"WALKING\", \"WALKING\"]\n",
    "recent_predictions_unstable = [\"RUNNING\", \"WALKING\", \"RUNNING\", \"WALKING\"]\n",
    "\n",
    "print(\"Stable sequence unstable?:\", is_unstable(recent_predictions_stable))\n",
    "print(\"Unstable sequence unstable?:\", is_unstable(recent_predictions_unstable))\n",
    "\n",
    "base_event = UXEvent(\n",
    "    event_type=\"SHOW_ALERT\",\n",
    "    message=\"Risky activity detected.\",\n",
    "    severity=\"high\",\n",
    "    metadata={}\n",
    ")\n",
    "\n",
    "print(\"Event without failsafe:\", base_event)\n",
    "print(\"Event with failsafe:\", apply_failsafe(base_event, unstable=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb840ecf-0407-40d0-99e1-2a16494b29ba",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "Observe how the failsafe logic changes system behaviour.\n",
    "Why is it important to downgrade alerts when predictions are unstable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df19f76-a274-47e6-ab6c-87d7ee10b0e4",
   "metadata": {},
   "source": [
    "## Lab Step 3 – Human-in-the-Loop (HITL) Integration\n",
    "\n",
    "In this step, you will add a human decision point to the AI workflow.\n",
    "The system will request confirmation or allow override before executing certain actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fc630-a783-4563-a5b6-72aece5d5f9b",
   "metadata": {},
   "source": [
    "### 3.1 Human Confirmation and Override\n",
    "\n",
    "Human-in-the-Loop mechanisms allow users or supervisors to confirm or cancel AI-generated events.\n",
    "This is especially important when actions are safety-critical or uncertainty is high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d0a491-9b47-4fd5-95a0-e914473a2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_decision(event: UXEvent, simulated_response: str = \"CONFIRM\") -> UXEvent:\n",
    "    \"\"\"\n",
    "    Simulates a human response to an AI-generated event.\n",
    "    simulated_response can be: 'CONFIRM' or 'CANCEL'\n",
    "    \"\"\"\n",
    "    if event.event_type != \"REQUEST_CONFIRMATION\":\n",
    "        return event\n",
    "\n",
    "    if simulated_response == \"CONFIRM\":\n",
    "        return UXEvent(\n",
    "            event_type=\"SHOW_ALERT\",\n",
    "            message=\"Alert confirmed by user.\",\n",
    "            severity=\"high\",\n",
    "            metadata=event.metadata\n",
    "        )\n",
    "\n",
    "    return UXEvent(\n",
    "        event_type=\"NO_ACTION\",\n",
    "        message=\"Alert cancelled by user.\",\n",
    "        severity=\"low\",\n",
    "        metadata=event.metadata\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf0890-92f3-4a31-9fb9-2b902dae266d",
   "metadata": {},
   "source": [
    "### 3.2 End-to-End HITL Simulation\n",
    "\n",
    "We now simulate the full decision chain:\n",
    "prediction → UX event → failsafe → human confirmation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40b789d-3e63-450b-96fb-66c130ec066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base event: UXEvent(event_type='SHOW_ALERT', message='Risky activity detected in restricted area.', severity='high', metadata={'activity': 'RUNNING', 'confidence': 0.85, 'restricted_area': True})\n",
      "After failsafe: UXEvent(event_type='REQUEST_CONFIRMATION', message='Unstable detection – user confirmation required.', severity='medium', metadata={'activity': 'RUNNING', 'confidence': 0.85, 'restricted_area': True})\n",
      "After HITL: UXEvent(event_type='SHOW_ALERT', message='Alert confirmed by user.', severity='high', metadata={'activity': 'RUNNING', 'confidence': 0.85, 'restricted_area': True})\n"
     ]
    }
   ],
   "source": [
    "# Base prediction scenario\n",
    "activity = \"RUNNING\"\n",
    "confidence = 0.85\n",
    "restricted_area = True\n",
    "\n",
    "# Step 1: prediction to UX event\n",
    "base_event = map_prediction_to_event(activity, confidence, restricted_area)\n",
    "\n",
    "# Step 2: failsafe logic\n",
    "recent_predictions = [\"RUNNING\", \"WALKING\", \"RUNNING\", \"WALKING\"]\n",
    "unstable = is_unstable(recent_predictions)\n",
    "safe_event = apply_failsafe(base_event, unstable)\n",
    "\n",
    "# Step 3: human-in-the-loop\n",
    "final_event = human_decision(safe_event, simulated_response=\"CONFIRM\")\n",
    "\n",
    "print(\"Base event:\", base_event)\n",
    "print(\"After failsafe:\", safe_event)\n",
    "print(\"After HITL:\", final_event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221e16-4e1c-4802-8ba5-b154697276af",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "Observe how the final system decision depends on both AI logic and human input.\n",
    "Why is this combination important for safety-critical applications?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3f4e1-03c2-4cac-b9eb-2f3eba801431",
   "metadata": {},
   "source": [
    "## Lab Step 4 - End-to-End Integration: From Sensor Data to Safe Action\n",
    "\n",
    "In this final lab step, we connect everything into a single end-to-end pipeline:\n",
    "\n",
    "1. Sensor data input  \n",
    "2. On-device model inference  \n",
    "3. Secure inference and validation (Safe Inference API)  \n",
    "4. Decision logic and UX mapping  \n",
    "5. Failsafe mechanisms  \n",
    "6. Human-in-the-Loop interaction  \n",
    "7. Final system action  \n",
    "\n",
    "Goal: run a realistic flow using the real model and (optionally) real data, while keeping the notebook runnable even if some artifacts are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b38c20-04bb-4a85-aeb0-bc40d67981c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Optional, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547129b8-8824-4dc4-bcd5-754d17973561",
   "metadata": {},
   "source": [
    "### 4.1 Sensor Data Input\n",
    "\n",
    "In this step, we load a sensor window from a dataset (preferably the benchmark windows created in Unit 2.1/2.2) or generate a synthetic window if no dataset is available. \n",
    "\n",
    "- **Dataset Loading:** If available, we load sensor data (in this case, from an NPZ file) using the appropriate keys. The sensor window (`X_window`) is loaded and its shape and data type are printed for inspection.\n",
    "- **Synthetic Data:** If no dataset is found, a synthetic window matching the model's input shape will be generated to allow further testing of the pipeline.\n",
    "\n",
    "**Important Notes:**\n",
    "1. **Window Size and Shape:** The `X_window` data is expected to match the dimensions `(W, C)`, where `W` is the window length and `C` is the number of channels. \n",
    "2. **Data Type:** The window's data type should be `float32` to be compatible with the model.\n",
    "3. **Range and Normalization:** In this example, the loaded window data shows large magnitude values, which may affect model validation. If necessary, we will normalize or scale the data to ensure proper model functioning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb70c6df-63d3-4049-9702-2e53f071f6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded window from NPZ key 'X_test' with shape (100, 7)\n",
      "X_window dtype: float32\n",
      "Any NaN?: False\n",
      "Any Inf?: False\n",
      "X_window min/max: -5.519999980926514 1007.5\n",
      "WARNING: The loaded window looks unscaled (large magnitude values).\n",
      "We will use a synthetic or normalized window later to avoid validation failures.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "NPZ_PATH = os.path.join(DATA_DIR, \"uca_ehar_preprocessed_win100_step50.npz\")\n",
    "\n",
    "# ---------- Load one window ----------\n",
    "X_window = None\n",
    "loaded_key = None\n",
    "\n",
    "if os.path.exists(NPZ_PATH):\n",
    "    npz = np.load(NPZ_PATH, allow_pickle=False)\n",
    "\n",
    "    # Try these keys in order (common patterns)\n",
    "    candidate_keys = [\"X_bench\", \"X_test\", \"X\", \"X_windows\"]\n",
    "\n",
    "    for k in candidate_keys:\n",
    "        if k in npz:\n",
    "            X = npz[k]\n",
    "            # Expect (N, W, C)\n",
    "            if isinstance(X, np.ndarray) and X.ndim == 3 and X.shape[0] > 0:\n",
    "                X_window = X[0].astype(np.float32)  # (W, C)\n",
    "                loaded_key = k\n",
    "                break\n",
    "\n",
    "if X_window is None:\n",
    "    print(\"No dataset window found. We will generate a synthetic window in Step 4.2.\")\n",
    "else:\n",
    "    print(f\"Loaded window from NPZ key '{loaded_key}' with shape {X_window.shape}\")\n",
    "\n",
    "# ---------- Sanity checks ----------\n",
    "if X_window is not None:\n",
    "    print(\"X_window dtype:\", X_window.dtype)\n",
    "    print(\"Any NaN?:\", bool(np.isnan(X_window).any()))\n",
    "    print(\"Any Inf?:\", bool(np.isinf(X_window).any()))\n",
    "    mn, mx = float(np.min(X_window)), float(np.max(X_window))\n",
    "    print(\"X_window min/max:\", mn, mx)\n",
    "\n",
    "    # This is only a diagnostic threshold. We do NOT modify data here.\n",
    "    if mx > 20 or mn < -20:\n",
    "        print(\"WARNING: The loaded window looks unscaled (large magnitude values).\")\n",
    "        print(\"We will use a synthetic or normalized window later to avoid validation failures.\")\n",
    "    else:\n",
    "        print(\"The loaded window magnitude looks reasonable for normalized IMU input.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e706b-795e-4464-9127-f3f720b10a21",
   "metadata": {},
   "source": [
    "### 4.2 On-Device Model Inference\n",
    "\n",
    "In this step, we load the optimized on-device model produced in **Unit 2.1** and run a **baseline inference pass**.\n",
    "\n",
    "At this stage:\n",
    "- We do **not** apply any secure validation or safety logic.\n",
    "- We intentionally observe the **raw model behavior**.\n",
    "- This establishes a baseline before introducing the secure inference layer in Step 4.3.\n",
    "\n",
    "The goal is to understand:\n",
    "- How the model expects its inputs\n",
    "- What the raw outputs look like\n",
    "- How predictions and confidence scores are derived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd92480-5efc-4c78-8e60-3dd02c7da333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model loaded successfully ✅\n",
      "Input name : input\n",
      "Input shape: ['unk__121', 100, 7]\n",
      "Output name: dense_1\n",
      "Output shape: ['unk__122', 8]\n",
      "\n",
      "Prepared inference input\n",
      "Inference input shape: (1, 100, 7)\n",
      "Inference input dtype: float32\n",
      "\n",
      "Raw model output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Predicted class: 5\n",
      "Confidence score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Model loading\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "MODELS_DIR = os.path.join(\"..\", \"models\")\n",
    "BASELINE_MODEL_PATH = os.path.join(MODELS_DIR, \"har_baseline.onnx\")\n",
    "\n",
    "assert os.path.exists(BASELINE_MODEL_PATH), f\"Model not found at: {BASELINE_MODEL_PATH}\"\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    BASELINE_MODEL_PATH,\n",
    "    providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "input_tensor = session.get_inputs()[0]\n",
    "output_tensor = session.get_outputs()[0]\n",
    "\n",
    "input_name = input_tensor.name\n",
    "output_name = output_tensor.name\n",
    "input_shape = input_tensor.shape  # e.g. ['unk__121', 100, 7]\n",
    "\n",
    "print(\"Baseline model loaded successfully ✅\")\n",
    "print(\"Input name :\", input_name)\n",
    "print(\"Input shape:\", input_shape)\n",
    "print(\"Output name:\", output_name)\n",
    "print(\"Output shape:\", output_tensor.shape)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Prepare input for inference\n",
    "# ---------------------------------------------------------------------\n",
    "# Model expects input shape (1, W, C)\n",
    "\n",
    "X_input = X_window[np.newaxis, :, :].astype(np.float32)\n",
    "\n",
    "print(\"\\nPrepared inference input\")\n",
    "print(\"Inference input shape:\", X_input.shape)\n",
    "print(\"Inference input dtype:\", X_input.dtype)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Run baseline (non-secure) inference\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "raw_output = session.run(\n",
    "    [output_name],\n",
    "    {input_name: X_input}\n",
    ")[0]\n",
    "\n",
    "predicted_class = int(np.argmax(raw_output))\n",
    "confidence = float(np.max(raw_output))\n",
    "\n",
    "print(\"\\nRaw model output:\", raw_output)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Confidence score:\", confidence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a47d836-0f8e-4e55-ac7e-126488529bc8",
   "metadata": {},
   "source": [
    "### 4.3 Secure Inference and Validation\n",
    "\n",
    "In this step, we run inference through a **secure validation layer**.\n",
    "\n",
    "Why this matters:\n",
    "- Real sensor inputs may be malformed (wrong shape/dtype), contain NaNs/Infs, or be outside the expected value range.\n",
    "- A secure wrapper prevents unsafe inputs from reaching the model and returns a **structured result** that downstream logic can handle safely.\n",
    "\n",
    "We follow a **hybrid approach**:\n",
    "- **Preferred:** reuse `secure_predict()` from Unit 2.2 (`src/edge_inference_secure.py`) if available.\n",
    "- **Fallback:** use a minimal `secure_predict()` implemented in this notebook.\n",
    "\n",
    "Important:  \n",
    "In Step 4.1 we detected that the dataset window may be **unscaled** (very large magnitudes).  \n",
    "To keep the pipeline stable, we also build a **safe window** (synthetic, normalized) and test secure inference on both:\n",
    "1. `X_window` (dataset window, may be unscaled)\n",
    "2. `X_window_safe` (guaranteed valid window for the model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b72030-0a86-455c-a70f-5b3d8d3d5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported secure_predict() from src.edge_inference_secure ✅\n",
      "\n",
      "--- Secure inference on dataset window (X_window) ---\n",
      "Result: {'ok': False, 'error': 'out_of_range_expected_-4.0_to_4.0', 'prediction': None, 'confidence': None}\n",
      "\n",
      "--- Secure inference on safe window (X_window_safe) ---\n",
      "Result: {'ok': True, 'error': None, 'prediction': 1, 'confidence': 0.18003952503204346}\n",
      "\n",
      "Selected secure_result for downstream steps: {'ok': True, 'error': None, 'prediction': 1, 'confidence': 0.18003952503204346}\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (A) Ensure repo root is on sys.path (so we can import src/ from notebooks/)\n",
    "# ---------------------------------------------------------------------\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (B) Derive expected (W, C) from the model input metadata\n",
    "#     input_shape is like ['unk__121', 100, 7]\n",
    "# ---------------------------------------------------------------------\n",
    "_, W, C = input_shape\n",
    "W, C = int(W), int(C)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (C) Build a \"safe\" window that is guaranteed to pass validation\n",
    "#     (synthetic normalized IMU-like data in [-1, 1])\n",
    "# ---------------------------------------------------------------------\n",
    "rng = np.random.default_rng(0)\n",
    "X_window_safe = rng.uniform(-1.0, 1.0, size=(W, C)).astype(np.float32)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (D) Local (fallback) validation + secure predict\n",
    "# ---------------------------------------------------------------------\n",
    "def validate_window_local(window: np.ndarray,\n",
    "                          expected_shape=(W, C),\n",
    "                          expected_dtype=np.float32,\n",
    "                          min_value=-4.0,\n",
    "                          max_value=4.0):\n",
    "    if not isinstance(window, np.ndarray):\n",
    "        return False, \"not_numpy_array\"\n",
    "    if window.shape != expected_shape:\n",
    "        return False, f\"wrong_shape_expected_{expected_shape}_got_{window.shape}\"\n",
    "    if window.dtype != expected_dtype:\n",
    "        return False, f\"wrong_dtype_expected_{expected_dtype}_got_{window.dtype}\"\n",
    "    if not np.isfinite(window).all():\n",
    "        return False, \"contains_nan_or_inf\"\n",
    "    mn, mx = float(window.min()), float(window.max())\n",
    "    if mn < min_value or mx > max_value:\n",
    "        return False, f\"out_of_range_expected_{min_value}_to_{max_value}_got_{mn:.3f}_to_{mx:.3f}\"\n",
    "    return True, None\n",
    "\n",
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    x = x - np.max(x)\n",
    "    ex = np.exp(x)\n",
    "    return ex / (np.sum(ex) + 1e-12)\n",
    "\n",
    "def secure_predict_fallback(session, input_name: str, output_name: str, window: np.ndarray):\n",
    "    ok, err = validate_window_local(window)\n",
    "    if not ok:\n",
    "        return {\"ok\": False, \"error\": err, \"prediction\": None, \"confidence\": None}\n",
    "\n",
    "    x = window[None, :, :].astype(np.float32)  # (1, W, C)\n",
    "    out = session.run([output_name], {input_name: x})[0][0]  # (num_classes,)\n",
    "\n",
    "    probs = softmax(out)\n",
    "    pred = int(np.argmax(probs))\n",
    "    conf = float(probs[pred])\n",
    "\n",
    "    return {\"ok\": True, \"error\": None, \"prediction\": pred, \"confidence\": conf}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (E) Preferred: try to import secure_predict from src (Unit 2.2)\n",
    "#     If it fails (missing / still stub / raises errors), we fall back.\n",
    "# ---------------------------------------------------------------------\n",
    "secure_predict_src = None\n",
    "try:\n",
    "    from src.edge_inference_secure import secure_predict as secure_predict_src\n",
    "    print(\"Imported secure_predict() from src.edge_inference_secure ✅\")\n",
    "except Exception as e:\n",
    "    print(\"Could not import src.secure_predict(). Will use fallback. Reason:\", repr(e))\n",
    "\n",
    "def secure_predict_hybrid(session, input_name: str, output_name: str, window: np.ndarray):\n",
    "    if secure_predict_src is not None:\n",
    "        try:\n",
    "            # Note: src implementation should accept (session, input_name, output_name, window)\n",
    "            return secure_predict_src(session, input_name, output_name, window)\n",
    "        except NotImplementedError:\n",
    "            print(\"[hybrid] src.secure_predict is a placeholder. Using fallback.\")\n",
    "        except Exception as e:\n",
    "            print(\"[hybrid] src.secure_predict failed. Using fallback. Reason:\", repr(e))\n",
    "    return secure_predict_fallback(session, input_name, output_name, window)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# (F) Run secure inference on:\n",
    "#     1) dataset window (may fail validation due to scaling)\n",
    "#     2) safe synthetic window (should pass)\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"\\n--- Secure inference on dataset window (X_window) ---\")\n",
    "result_dataset = secure_predict_hybrid(session, input_name, output_name, X_window)\n",
    "print(\"Result:\", result_dataset)\n",
    "\n",
    "print(\"\\n--- Secure inference on safe window (X_window_safe) ---\")\n",
    "result_safe = secure_predict_hybrid(session, input_name, output_name, X_window_safe)\n",
    "print(\"Result:\", result_safe)\n",
    "\n",
    "# We'll use the safe result for downstream steps if the dataset one is rejected.\n",
    "secure_result = result_dataset if result_dataset[\"ok\"] else result_safe\n",
    "print(\"\\nSelected secure_result for downstream steps:\", secure_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd582e08-d602-4f36-b988-a3fe943c1cb6",
   "metadata": {},
   "source": [
    "### 4.4 Decision Logic and UX Mapping\n",
    "\n",
    "At this stage, the system has a *secure inference result* produced by the Safe Inference layer.\n",
    "\n",
    "The goal of this step is to translate the model output into a **user-facing decision**, taking into account:\n",
    "- Whether inference was successful\n",
    "- The predicted class\n",
    "- The confidence score\n",
    "- Conservative safety thresholds\n",
    "\n",
    "This logic bridges **ML outputs** and **UX/system behavior**, which is a critical aspect of on-device AI systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4070b7f3-1982-4f8d-931c-3970176bb1c1",
   "metadata": {},
   "source": [
    "#### Decision Policy\n",
    "\n",
    "We apply the following simple policy:\n",
    "\n",
    "- If inference failed → **No Action**\n",
    "- If confidence ≥ high threshold → **Automatic Action**\n",
    "- If confidence is moderate → **Request Human Confirmation**\n",
    "- If confidence is low → **No Action (failsafe)**\n",
    "\n",
    "These thresholds are illustrative and would normally be tuned per application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c1747b-8927-4cc3-bd6e-5e36884e1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_logic(secure_result,\n",
    "                   high_conf_threshold=0.7,\n",
    "                   low_conf_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Map secure inference results to UX/system actions.\n",
    "    \n",
    "    Returns a dictionary describing the chosen action.\n",
    "    \"\"\"\n",
    "\n",
    "    if not secure_result.get(\"ok\", False):\n",
    "        return {\n",
    "            \"action\": \"NO_ACTION\",\n",
    "            \"reason\": \"Inference failed\",\n",
    "            \"prediction\": None,\n",
    "            \"confidence\": None\n",
    "        }\n",
    "\n",
    "    confidence = secure_result.get(\"confidence\", 0.0)\n",
    "    prediction = secure_result.get(\"prediction\")\n",
    "\n",
    "    if confidence >= high_conf_threshold:\n",
    "        return {\n",
    "            \"action\": \"AUTO_CONFIRM\",\n",
    "            \"reason\": \"High confidence prediction\",\n",
    "            \"prediction\": prediction,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    if confidence >= low_conf_threshold:\n",
    "        return {\n",
    "            \"action\": \"REQUEST_CONFIRMATION\",\n",
    "            \"reason\": \"Medium confidence prediction\",\n",
    "            \"prediction\": prediction,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"action\": \"NO_ACTION\",\n",
    "        \"reason\": \"Low confidence prediction (failsafe)\",\n",
    "        \"prediction\": prediction,\n",
    "        \"confidence\": confidence\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77a3bd6-bede-416a-9bd0-8bf5c118873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision logic output:\n",
      "  action: NO_ACTION\n",
      "  reason: Low confidence prediction (failsafe)\n",
      "  prediction: 1\n",
      "  confidence: 0.18003952503204346\n"
     ]
    }
   ],
   "source": [
    "decision = decision_logic(secure_result)\n",
    "\n",
    "print(\"Decision logic output:\")\n",
    "for k, v in decision.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c27c6d2-903d-40be-926d-851994e5898e",
   "metadata": {},
   "source": [
    "#### Expected Outcome\n",
    "\n",
    "Depending on the confidence level produced in Step 4.3, the system will:\n",
    "\n",
    "- Automatically confirm the prediction\n",
    "- Ask for human confirmation\n",
    "- Or take no action at all\n",
    "\n",
    "This ensures that **model uncertainty does not directly translate into unsafe or confusing user experiences**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0141d7-798b-49e1-9228-5e9281e6c946",
   "metadata": {},
   "source": [
    "### 4.5 Failsafe Mechanisms\n",
    "\n",
    "Even with secure validation, on-device predictions can still be *uncertain* (low confidence) or *unstable* (confidence fluctuates).\n",
    "\n",
    "Failsafe mechanisms ensure the system behaves conservatively by:\n",
    "- suppressing actions when confidence is low\n",
    "- requiring repeated agreement over multiple windows (“stability over time”)\n",
    "- preventing repeated triggers (“cooldown”)\n",
    "\n",
    "In this step we run two mini-simulations:\n",
    "\n",
    "1) **Realistic stream (based on the current secure result):**  \n",
    "   Confidence remains low, so the system should consistently choose **NO_ACTION**.\n",
    "\n",
    "2) **Demonstration stream (intentionally mixed):**  \n",
    "   We inject a short high-confidence streak to show how the failsafe gate:\n",
    "   - only allows action after **K consecutive high-confidence windows**\n",
    "   - applies **cooldown** after an action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab889c6-5196-4fe9-9034-2edf2db39a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Simulation 1 (Realistic): Low-confidence stream → conservative behavior ===\n",
      "Confidence stream:\n",
      "[0.208, 0.246, 0.206, 0.076, 0.252, 0.216, 0.137, 0.227, 0.209, 0.204, 0.182, 0.224]\n",
      "Proposed actions (before failsafe):\n",
      "['NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION']\n",
      "Gated actions (after failsafe):\n",
      "['NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION']\n",
      "\n",
      "=== Simulation 2 (Demo): High-confidence streak → gated AUTO_CONFIRM + cooldown ===\n",
      "Confidence stream:\n",
      "[0.25, 0.35, 0.55, 0.72, 0.78, 0.81, 0.85, 0.9, 0.4, 0.2, 0.75, 0.8, 0.82]\n",
      "Proposed actions (before failsafe):\n",
      "['NO_ACTION', 'REQUEST_CONFIRMATION', 'REQUEST_CONFIRMATION', 'AUTO_CONFIRM', 'AUTO_CONFIRM', 'AUTO_CONFIRM', 'AUTO_CONFIRM', 'AUTO_CONFIRM', 'REQUEST_CONFIRMATION', 'NO_ACTION', 'AUTO_CONFIRM', 'AUTO_CONFIRM', 'AUTO_CONFIRM']\n",
      "Gated actions (after failsafe):\n",
      "['NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'AUTO_CONFIRM', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'NO_ACTION', 'AUTO_CONFIRM']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def failsafe_gate(decisions,\n",
    "                  require_consecutive=3,\n",
    "                  min_conf_for_action=0.7,\n",
    "                  cooldown_steps=5):\n",
    "    \"\"\"\n",
    "    Apply failsafe gating on a sequence of decisions.\n",
    "\n",
    "    Policy:\n",
    "    - Only allow AUTO_CONFIRM if confidence >= min_conf_for_action for\n",
    "      `require_consecutive` consecutive windows.\n",
    "    - After an allowed AUTO_CONFIRM, enforce a cooldown period where actions\n",
    "      are suppressed (NO_ACTION).\n",
    "\n",
    "    Returns:\n",
    "      gated_actions: list of action strings after failsafe gating\n",
    "    \"\"\"\n",
    "    gated_actions = []\n",
    "    streak = 0\n",
    "    cooldown = 0\n",
    "\n",
    "    for d in decisions:\n",
    "        conf = d.get(\"confidence\") if d.get(\"confidence\") is not None else 0.0\n",
    "        proposed = d.get(\"action\", \"NO_ACTION\")\n",
    "\n",
    "        if cooldown > 0:\n",
    "            gated_actions.append(\"NO_ACTION\")\n",
    "            cooldown -= 1\n",
    "            streak = 0\n",
    "            continue\n",
    "\n",
    "        if conf >= min_conf_for_action:\n",
    "            streak += 1\n",
    "        else:\n",
    "            streak = 0\n",
    "\n",
    "        if proposed == \"AUTO_CONFIRM\" and streak >= require_consecutive:\n",
    "            gated_actions.append(\"AUTO_CONFIRM\")\n",
    "            cooldown = cooldown_steps\n",
    "            streak = 0\n",
    "        else:\n",
    "            gated_actions.append(\"NO_ACTION\")\n",
    "\n",
    "    return gated_actions\n",
    "\n",
    "def propose_action_from_conf(conf: float) -> str:\n",
    "    \"\"\"Simple proposal policy before failsafe gating.\"\"\"\n",
    "    if conf >= 0.7:\n",
    "        return \"AUTO_CONFIRM\"\n",
    "    if conf >= 0.3:\n",
    "        return \"REQUEST_CONFIRMATION\"\n",
    "    return \"NO_ACTION\"\n",
    "\n",
    "def run_simulation(conf_stream, title, require_consecutive=3, cooldown_steps=3):\n",
    "    proposed_decisions = []\n",
    "    for c in conf_stream:\n",
    "        proposed_decisions.append({\n",
    "            \"action\": propose_action_from_conf(float(c)),\n",
    "            \"confidence\": float(c),\n",
    "            \"prediction\": secure_result.get(\"prediction\", None),\n",
    "            \"reason\": \"simulated\"\n",
    "        })\n",
    "\n",
    "    gated = failsafe_gate(\n",
    "        proposed_decisions,\n",
    "        require_consecutive=require_consecutive,\n",
    "        min_conf_for_action=0.7,\n",
    "        cooldown_steps=cooldown_steps\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(\"Confidence stream:\")\n",
    "    print([round(float(c), 3) for c in conf_stream])\n",
    "    print(\"Proposed actions (before failsafe):\")\n",
    "    print([d[\"action\"] for d in proposed_decisions])\n",
    "    print(\"Gated actions (after failsafe):\")\n",
    "    print(gated)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Simulation 1: Realistic stream around current secure_result confidence\n",
    "# -------------------------------------------------------------\n",
    "rng = np.random.default_rng(1)\n",
    "base_conf = float(secure_result.get(\"confidence\") or 0.0)\n",
    "conf_stream_realistic = np.clip(base_conf + rng.normal(0, 0.08, size=12), 0.0, 1.0)\n",
    "\n",
    "run_simulation(\n",
    "    conf_stream_realistic,\n",
    "    title=\"Simulation 1 (Realistic): Low-confidence stream → conservative behavior\",\n",
    "    require_consecutive=3,\n",
    "    cooldown_steps=3\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Simulation 2: Demonstration stream that includes a high-confidence streak\n",
    "# (to show the gate + cooldown in action)\n",
    "# -------------------------------------------------------------\n",
    "conf_stream_demo = np.array([\n",
    "    0.25, 0.35, 0.55,   # includes REQUEST_CONFIRMATION, but not AUTO_CONFIRM\n",
    "    0.72, 0.78, 0.81,   # 3 consecutive highs → AUTO_CONFIRM allowed once\n",
    "    0.85, 0.90,         # would be high, but cooldown suppresses\n",
    "    0.40, 0.20,         # drop back down\n",
    "    0.75, 0.80, 0.82    # another streak → may allow again after cooldown\n",
    "], dtype=np.float32)\n",
    "\n",
    "run_simulation(\n",
    "    conf_stream_demo,\n",
    "    title=\"Simulation 2 (Demo): High-confidence streak → gated AUTO_CONFIRM + cooldown\",\n",
    "    require_consecutive=3,\n",
    "    cooldown_steps=3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f8401-f1df-4142-858a-005be5b27e9a",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- The **realistic simulation** often results in NO_ACTION throughout, which is expected when the model is uncertain.\n",
    "- The **demo simulation** proves the failsafe logic works:\n",
    "  - actions are only allowed after stable high confidence\n",
    "  - cooldown prevents repeated triggers\n",
    "\n",
    "This reinforces the engineering goal: **prefer conservative behavior unless the model is consistently confident.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85845e15-e5d8-4085-812d-b52150deef3b",
   "metadata": {},
   "source": [
    "### 4.6 Human-in-the-Loop Interaction\n",
    "\n",
    "Even with secure validation and failsafe gating, edge AI systems often require a **Human-in-the-Loop (HITL)** mechanism.\n",
    "\n",
    "Why HITL matters:\n",
    "- Some decisions are safety-critical or ambiguous.\n",
    "- Confidence may be moderate (not high enough for automatic action).\n",
    "- The system may need confirmation, correction, or override.\n",
    "\n",
    "In this step, we simulate a HITL workflow:\n",
    "\n",
    "- If the system proposes `REQUEST_CONFIRMATION`, we ask for a user confirmation.\n",
    "- Since this is a notebook, we simulate human feedback with a simple function:\n",
    "  - In **realistic mode**, the human may reject uncertain predictions.\n",
    "  - In **demo mode**, we show both accept and reject outcomes.\n",
    "\n",
    "The output is a final decision that can be executed safely in Step 4.7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb618ebc-3d33-4402-81b9-26ed79ea084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Realistic case (using current decision) ===\n",
      "  action: NO_ACTION\n",
      "  reason: Low confidence prediction (failsafe)\n",
      "  prediction: 1\n",
      "  confidence: 0.18003952503204346\n",
      "  final_action: NO_ACTION\n",
      "  hitl_used: False\n",
      "  human_response: None\n",
      "\n",
      "=== Demo case (REQUEST_CONFIRMATION) - Human says YES ===\n",
      "  action: REQUEST_CONFIRMATION\n",
      "  reason: Medium confidence prediction\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  final_action: CONFIRMED_BY_HUMAN\n",
      "  hitl_used: True\n",
      "  human_response: YES\n",
      "\n",
      "=== Demo case (REQUEST_CONFIRMATION) - Human says NO ===\n",
      "  action: REQUEST_CONFIRMATION\n",
      "  reason: Medium confidence prediction\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  final_action: REJECTED_BY_HUMAN\n",
      "  hitl_used: True\n",
      "  human_response: NO\n",
      "\n",
      "=== Demo case (REQUEST_CONFIRMATION) - No response (timeout) ===\n",
      "  action: REQUEST_CONFIRMATION\n",
      "  reason: Medium confidence prediction | No human response (timeout)\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  final_action: NO_ACTION\n",
      "  hitl_used: True\n",
      "  human_response: None\n"
     ]
    }
   ],
   "source": [
    "def human_in_loop(decision,\n",
    "                  human_response=None,\n",
    "                  default_on_no_response=\"NO_ACTION\"):\n",
    "    \"\"\"\n",
    "    Simulate Human-in-the-Loop confirmation.\n",
    "\n",
    "    Inputs:\n",
    "      - decision: dict from decision_logic()\n",
    "      - human_response: one of {\"YES\", \"NO\", None}\n",
    "        * YES: accept prediction\n",
    "        * NO : reject prediction\n",
    "        * None: no response / timeout\n",
    "      - default_on_no_response: fallback action if no response\n",
    "\n",
    "    Returns:\n",
    "      final_decision: dict with final action\n",
    "    \"\"\"\n",
    "    action = decision.get(\"action\", \"NO_ACTION\")\n",
    "\n",
    "    # Only intervene when system requests confirmation\n",
    "    if action != \"REQUEST_CONFIRMATION\":\n",
    "        return {\n",
    "            **decision,\n",
    "            \"final_action\": action,\n",
    "            \"hitl_used\": False,\n",
    "            \"human_response\": None\n",
    "        }\n",
    "\n",
    "    # Handle human response\n",
    "    if human_response == \"YES\":\n",
    "        return {\n",
    "            **decision,\n",
    "            \"final_action\": \"CONFIRMED_BY_HUMAN\",\n",
    "            \"hitl_used\": True,\n",
    "            \"human_response\": \"YES\"\n",
    "        }\n",
    "\n",
    "    if human_response == \"NO\":\n",
    "        return {\n",
    "            **decision,\n",
    "            \"final_action\": \"REJECTED_BY_HUMAN\",\n",
    "            \"hitl_used\": True,\n",
    "            \"human_response\": \"NO\"\n",
    "        }\n",
    "\n",
    "    # No response / timeout\n",
    "    return {\n",
    "        **decision,\n",
    "        \"final_action\": default_on_no_response,\n",
    "        \"hitl_used\": True,\n",
    "        \"human_response\": None,\n",
    "        \"reason\": (decision.get(\"reason\", \"\") + \" | No human response (timeout)\").strip(\" |\")\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Realistic case: use the decision we already computed in Step 4.4\n",
    "# (Often NO_ACTION when confidence is low)\n",
    "# -------------------------------------------------------------\n",
    "final_realistic = human_in_loop(decision, human_response=None)\n",
    "\n",
    "print(\"=== Realistic case (using current decision) ===\")\n",
    "for k, v in final_realistic.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Demo case: force a REQUEST_CONFIRMATION decision to show HITL behavior\n",
    "# -------------------------------------------------------------\n",
    "demo_decision_request = {\n",
    "    \"action\": \"REQUEST_CONFIRMATION\",\n",
    "    \"reason\": \"Medium confidence prediction\",\n",
    "    \"prediction\": secure_result.get(\"prediction\", 0),\n",
    "    \"confidence\": 0.55\n",
    "}\n",
    "\n",
    "final_demo_yes = human_in_loop(demo_decision_request, human_response=\"YES\")\n",
    "final_demo_no  = human_in_loop(demo_decision_request, human_response=\"NO\")\n",
    "final_demo_none = human_in_loop(demo_decision_request, human_response=None)\n",
    "\n",
    "print(\"\\n=== Demo case (REQUEST_CONFIRMATION) - Human says YES ===\")\n",
    "for k, v in final_demo_yes.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== Demo case (REQUEST_CONFIRMATION) - Human says NO ===\")\n",
    "for k, v in final_demo_no.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== Demo case (REQUEST_CONFIRMATION) - No response (timeout) ===\")\n",
    "for k, v in final_demo_none.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a44330-6b39-4b06-9c57-fbbf2c1dba58",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- In the **realistic case**, the system often produces `NO_ACTION`, so HITL is not invoked.\n",
    "- In the **demo case**, we show how HITL:\n",
    "  - confirms uncertain predictions (`CONFIRMED_BY_HUMAN`)\n",
    "  - rejects them (`REJECTED_BY_HUMAN`)\n",
    "  - or defaults safely on timeout (`NO_ACTION`)\n",
    "\n",
    "This reflects real deployment patterns where edge AI systems must support **confirmation and override** rather than relying purely on automation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d17e3-2224-4dff-9dc8-818593f63dd5",
   "metadata": {},
   "source": [
    "### 4.7 Final System Action\n",
    "\n",
    "In the final step, we convert the *final decision* into an explicit **system action**.\n",
    "\n",
    "The purpose is to ensure the pipeline ends with an output that is:\n",
    "- safe (never triggers on invalid/uncertain inputs)\n",
    "- interpretable (clear reason codes)\n",
    "- actionable (can be connected to UI, logs, or device behavior)\n",
    "\n",
    "We map the final decision into one of the following events:\n",
    "- `NO_ACTION` → do nothing (failsafe)\n",
    "- `AUTO_CONFIRM` / `CONFIRMED_BY_HUMAN` → trigger an application action (e.g., alert)\n",
    "- `REJECTED_BY_HUMAN` → record override and do nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342dea37-24e1-4842-8c57-0ccdb76b5da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System event (Realistic case) ===\n",
      "  event_type: NO_ACTION\n",
      "  message: No action taken.\n",
      "  prediction: 1\n",
      "  confidence: 0.18003952503204346\n",
      "  reason: Low confidence prediction (failsafe)\n",
      "\n",
      "=== System event (Demo YES) ===\n",
      "  event_type: TRIGGER_ALERT\n",
      "  message: Action triggered for class=1 (final_action=CONFIRMED_BY_HUMAN).\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  reason: Medium confidence prediction\n",
      "\n",
      "=== System event (Demo NO) ===\n",
      "  event_type: HUMAN_OVERRIDE\n",
      "  message: Human rejected the suggested prediction. No action taken.\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  reason: Medium confidence prediction\n",
      "\n",
      "=== System event (Demo timeout) ===\n",
      "  event_type: NO_ACTION\n",
      "  message: No action taken.\n",
      "  prediction: 1\n",
      "  confidence: 0.55\n",
      "  reason: Medium confidence prediction | No human response (timeout)\n"
     ]
    }
   ],
   "source": [
    "def map_to_system_event(final_decision):\n",
    "    \"\"\"\n",
    "    Convert a final decision dict into a system-level event.\n",
    "    \"\"\"\n",
    "    final_action = final_decision.get(\"final_action\", final_decision.get(\"action\", \"NO_ACTION\"))\n",
    "    prediction = final_decision.get(\"prediction\")\n",
    "    confidence = final_decision.get(\"confidence\")\n",
    "    reason = final_decision.get(\"reason\", \"\")\n",
    "\n",
    "    # Default event structure\n",
    "    event = {\n",
    "        \"event_type\": \"NO_ACTION\",\n",
    "        \"message\": \"No action taken.\",\n",
    "        \"prediction\": prediction,\n",
    "        \"confidence\": confidence,\n",
    "        \"reason\": reason\n",
    "    }\n",
    "\n",
    "    if final_action in (\"AUTO_CONFIRM\", \"CONFIRMED_BY_HUMAN\"):\n",
    "        event[\"event_type\"] = \"TRIGGER_ALERT\"\n",
    "        event[\"message\"] = f\"Action triggered for class={prediction} (final_action={final_action}).\"\n",
    "        return event\n",
    "\n",
    "    if final_action == \"REJECTED_BY_HUMAN\":\n",
    "        event[\"event_type\"] = \"HUMAN_OVERRIDE\"\n",
    "        event[\"message\"] = \"Human rejected the suggested prediction. No action taken.\"\n",
    "        return event\n",
    "\n",
    "    # NO_ACTION or timeout fallback → keep defaults\n",
    "    return event\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Realistic case: use the result from Step 4.6\n",
    "# -------------------------------------------------------------\n",
    "system_event_realistic = map_to_system_event(final_realistic)\n",
    "\n",
    "print(\"=== System event (Realistic case) ===\")\n",
    "for k, v in system_event_realistic.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Demo cases: show how the final system action changes\n",
    "# -------------------------------------------------------------\n",
    "system_event_demo_yes = map_to_system_event(final_demo_yes)\n",
    "system_event_demo_no = map_to_system_event(final_demo_no)\n",
    "system_event_demo_none = map_to_system_event(final_demo_none)\n",
    "\n",
    "print(\"\\n=== System event (Demo YES) ===\")\n",
    "for k, v in system_event_demo_yes.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== System event (Demo NO) ===\")\n",
    "for k, v in system_event_demo_no.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== System event (Demo timeout) ===\")\n",
    "for k, v in system_event_demo_none.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d01c7-7c25-4eb4-aadf-2d89621d94d7",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- The **realistic case** often produces `NO_ACTION`, which is appropriate when confidence is low.\n",
    "- The **demo YES** case produces a `TRIGGER_ALERT` event, showing how the system can act after confirmation.\n",
    "- The **demo NO** case produces a `HUMAN_OVERRIDE` event, demonstrating safe rejection.\n",
    "- The **timeout** case defaults safely to `NO_ACTION`.\n",
    "\n",
    "This completes the integrated pipeline end-to-end with safety-by-design behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba498c8-549e-49cc-8d5b-a2c172f7cb99",
   "metadata": {},
   "source": [
    "## Wrap-Up and Key Takeaways\n",
    "\n",
    "In this unit, you implemented and validated a **complete end-to-end secure AI pipeline**, moving beyond isolated model execution to a **system-level perspective**.\n",
    "\n",
    "### What You Built\n",
    "\n",
    "You integrated all core elements of a trustworthy on-device AI system:\n",
    "\n",
    "1. **Sensor data ingestion**  \n",
    "   - Real or synthetic sensor windows aligned with the model interface.\n",
    "\n",
    "2. **On-device model inference**  \n",
    "   - Execution of an optimized ONNX model with explicit inspection of inputs and outputs.\n",
    "\n",
    "3. **Secure inference and validation**  \n",
    "   - A safety layer ensuring correct shape, type, and value ranges before inference.\n",
    "   - Graceful handling of invalid or unsafe inputs.\n",
    "\n",
    "4. **Decision logic and UX mapping**  \n",
    "   - Translation of raw predictions into user-facing actions based on confidence thresholds.\n",
    "\n",
    "5. **Failsafe mechanisms**  \n",
    "   - Conservative behaviour under uncertainty, noise, or unstable confidence streams.\n",
    "\n",
    "6. **Human-in-the-Loop interaction**  \n",
    "   - Optional human confirmation, rejection, or timeout handling.\n",
    "\n",
    "7. **Final system action**  \n",
    "   - A safe, interpretable system event (alert, override, or no action).\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "This lab demonstrates that **AI systems are not models alone**.\n",
    "\n",
    "A production-ready AI solution must:\n",
    "- Be robust to invalid inputs\n",
    "- Avoid unsafe automation\n",
    "- Communicate uncertainty\n",
    "- Support human oversight\n",
    "- Fail safely by design\n",
    "\n",
    "These principles are essential in domains such as:\n",
    "- Wearables and health monitoring\n",
    "- Smart mobility and IoT\n",
    "- Industrial edge AI\n",
    "- Safety-critical human–machine interaction\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "> **Trustworthy AI emerges from system design, not model accuracy alone.**\n",
    "\n",
    "With this unit, you have completed **Module 2**, progressing from:\n",
    "- model optimization (Unit 2.1),\n",
    "- secure integration (Unit 2.2),\n",
    "- to full system orchestration (Unit 2.3).\n",
    "\n",
    "You are now ready to move forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dcaf4-ccd1-4663-8d53-7d33851fdec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
